{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "q0E7MmABuKbU",
   "metadata": {
    "id": "q0E7MmABuKbU"
   },
   "source": [
    "### **Intall Dependencies**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ex2-qbxVuAUV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18420,
     "status": "ok",
     "timestamp": 1770735075710,
     "user": {
      "displayName": "HEMAL MEWANTHA MUNASINGHA",
      "userId": "11358127870633125715"
     },
     "user_tz": -330
    },
    "id": "Ex2-qbxVuAUV",
    "outputId": "4d7687b8-1738-4dda-cfcf-de94916b7c14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf (from -r /content/drive/MyDrive/mini-project-01/requirements.txt (line 4))\n",
      "  Downloading pypdf-6.7.0-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/mini-project-01/requirements.txt (line 7)) (5.0.0)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/mini-project-01/requirements.txt (line 8)) (4.0.0)\n",
      "Requirement already satisfied: peft in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (0.18.1)\n",
      "Collecting trl (from -r /content/drive/MyDrive/mini-project-01/requirements.txt (line 10))\n",
      "  Downloading trl-0.28.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting bitsandbytes (from -r /content/drive/MyDrive/mini-project-01/requirements.txt (line 11))\n",
      "  Downloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: accelerate in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/mini-project-01/requirements.txt (line 12)) (1.12.0)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/mini-project-01/requirements.txt (line 15)) (2.2.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/mini-project-01/requirements.txt (line 16)) (2.0.2)\n",
      "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/mini-project-01/requirements.txt (line 19)) (5.2.2)\n",
      "Collecting weaviate-client (from -r /content/drive/MyDrive/mini-project-01/requirements.txt (line 22))\n",
      "  Downloading weaviate_client-4.19.2-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting langchain-openai (from -r /content/drive/MyDrive/mini-project-01/requirements.txt (line 25))\n",
      "  Downloading langchain_openai-1.1.8-py3-none-any.whl.metadata (3.1 kB)\n",
      "Collecting langchain-groq (from -r /content/drive/MyDrive/mini-project-01/requirements.txt (line 26))\n",
      "  Downloading langchain_groq-1.1.2-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-google-genai (from -r /content/drive/MyDrive/mini-project-01/requirements.txt (line 27))\n",
      "  Downloading langchain_google_genai-4.2.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-cohere (from -r /content/drive/MyDrive/mini-project-01/requirements.txt (line 28))\n",
      "  Downloading langchain_cohere-0.5.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting langchain-community (from -r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29))\n",
      "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (from -r /content/drive/MyDrive/mini-project-01/requirements.txt (line 32)) (1.2.8)\n",
      "Collecting rouge_score (from -r /content/drive/MyDrive/mini-project-01/requirements.txt (line 35))\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 7)) (3.20.3)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 7)) (1.3.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 7)) (26.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 7)) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 7)) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 7)) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from transformers->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 7)) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 7)) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 7)) (4.67.2)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 8)) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 8)) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 8)) (2.32.4)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 8)) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 8)) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 8)) (2025.3.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (5.9.5)\n",
      "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.12/dist-packages (from peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (2.9.0+cu126)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 15)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 15)) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 15)) (2025.3)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 19)) (1.6.1)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 19)) (1.16.3)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 19)) (4.15.0)\n",
      "Requirement already satisfied: httpx<0.29.0,>=0.26.0 in /usr/local/lib/python3.12/dist-packages (from weaviate-client->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 22)) (0.28.1)\n",
      "Collecting validators<1.0.0,>=0.34.0 (from weaviate-client->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 22))\n",
      "  Downloading validators-0.35.0-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: authlib<2.0.0,>=1.6.5 in /usr/local/lib/python3.12/dist-packages (from weaviate-client->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 22)) (1.6.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.12.0 in /usr/local/lib/python3.12/dist-packages (from weaviate-client->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 22)) (2.12.3)\n",
      "Requirement already satisfied: grpcio<1.80.0,>=1.59.5 in /usr/local/lib/python3.12/dist-packages (from weaviate-client->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 22)) (1.76.0)\n",
      "Requirement already satisfied: protobuf<7.0.0,>=4.21.6 in /usr/local/lib/python3.12/dist-packages (from weaviate-client->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 22)) (5.29.5)\n",
      "Requirement already satisfied: deprecation<3.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from weaviate-client->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 22)) (2.1.0)\n",
      "Collecting langchain-core<2.0.0,>=1.2.9 (from langchain-openai->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 25))\n",
      "  Downloading langchain_core-1.2.10-py3-none-any.whl.metadata (4.4 kB)\n",
      "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 25)) (2.16.0)\n",
      "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 25)) (0.12.0)\n",
      "Collecting groq<1.0.0,>=0.30.0 (from langchain-groq->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 26))\n",
      "  Downloading groq-0.37.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 27))\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in /usr/local/lib/python3.12/dist-packages (from langchain-google-genai->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 27)) (1.61.0)\n",
      "Collecting cohere<6.0,>=5.18.0 (from langchain-cohere->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 28))\n",
      "  Downloading cohere-5.20.4-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting types-pyyaml<7.0.0.0,>=6.0.12.20240917 (from langchain-cohere->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 28))\n",
      "  Downloading types_pyyaml-6.0.12.20250915-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29))\n",
      "  Downloading langchain_classic-1.0.1-py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29)) (2.0.46)\n",
      "Collecting requests>=2.32.2 (from datasets->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 8))\n",
      "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29)) (3.13.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29)) (9.1.2)\n",
      "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29))\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29)) (2.12.0)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29)) (0.6.8)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29)) (0.4.3)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langchain->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 32)) (1.0.7)\n",
      "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 35)) (1.4.0)\n",
      "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 35)) (3.9.1)\n",
      "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 35)) (1.17.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29)) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29)) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29)) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29)) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29)) (6.7.1)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29)) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29)) (1.22.0)\n",
      "Requirement already satisfied: cryptography in /usr/local/lib/python3.12/dist-packages (from authlib<2.0.0,>=1.6.5->weaviate-client->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 22)) (43.0.3)\n",
      "Collecting fastavro<2.0.0,>=1.9.4 (from cohere<6.0,>=5.18.0->langchain-cohere->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 28))\n",
      "  Downloading fastavro-1.12.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pydantic-core>=2.18.2 in /usr/local/lib/python3.12/dist-packages (from cohere<6.0,>=5.18.0->langchain-cohere->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 28)) (2.41.4)\n",
      "Collecting types-requests<3.0.0,>=2.0.0 (from cohere<6.0,>=5.18.0->langchain-cohere->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 28))\n",
      "  Downloading types_requests-2.32.4.20260107-py3-none-any.whl.metadata (2.0 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29))\n",
      "  Downloading marshmallow-3.26.2-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29))\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 27)) (4.12.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in /usr/local/lib/python3.12/dist-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 27)) (2.47.0)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 27)) (15.0.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 27)) (1.9.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 27)) (1.3.1)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 22)) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 22)) (1.0.9)\n",
      "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 22)) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<0.29.0,>=0.26.0->weaviate-client->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 22)) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 7)) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 7)) (1.5.4)\n",
      "Collecting langchain-text-splitters<2.0.0,>=1.1.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29))\n",
      "  Downloading langchain_text_splitters-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.9->langchain-openai->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 25)) (1.33)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.2.9->langchain-openai->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 25)) (0.14.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 32)) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 32)) (1.0.7)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph<1.1.0,>=1.0.7->langchain->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 32)) (0.3.3)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29)) (3.11.7)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29)) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29)) (0.25.0)\n",
      "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 25)) (0.13.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.12.0->weaviate-client->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 22)) (0.7.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.12.0->weaviate-client->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 22)) (0.4.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29)) (1.2.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 8)) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 8)) (2.5.0)\n",
      "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29)) (3.3.1)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (3.5.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 35)) (8.3.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 35)) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 19)) (3.6.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 27)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 27)) (4.9.1)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.9->langchain-openai->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 25)) (3.0.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.7->langchain->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 32)) (1.12.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (1.3.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 29))\n",
      "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography->authlib<2.0.0,>=1.6.5->weaviate-client->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 22)) (2.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.13.0->peft->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 9)) (3.0.3)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography->authlib<2.0.0,>=1.6.5->weaviate-client->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 22)) (3.0)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai->-r /content/drive/MyDrive/mini-project-01/requirements.txt (line 27)) (0.6.2)\n",
      "Downloading pypdf-6.7.0-py3-none-any.whl (330 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.6/330.6 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.28.0-py3-none-any.whl (540 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m540.5/540.5 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.49.1-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading weaviate_client-4.19.2-py3-none-any.whl (603 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m603.7/603.7 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_openai-1.1.8-py3-none-any.whl (84 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_groq-1.1.2-py3-none-any.whl (19 kB)\n",
      "Downloading langchain_google_genai-4.2.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/66.5 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_cohere-0.5.0-py3-none-any.whl (42 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cohere-5.20.4-py3-none-any.whl (318 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.0/319.0 kB\u001b[0m \u001b[31m36.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading groq-0.37.1-py3-none-any.whl (137 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_classic-1.0.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m73.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-1.2.10-py3-none-any.whl (496 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m496.7/496.7 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading types_pyyaml-6.0.12.20250915-py3-none-any.whl (20 kB)\n",
      "Downloading validators-0.35.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fastavro-1.12.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m125.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-1.1.0-py3-none-any.whl (34 kB)\n",
      "Downloading marshmallow-3.26.2-py3-none-any.whl (50 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.0/51.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading types_requests-2.32.4.20260107-py3-none-any.whl (20 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Building wheels for collected packages: rouge_score\n",
      "  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=105e01eb275139979d988b8adf64f5ac8272e476023b2b3c052ccb91709bd20d\n",
      "  Stored in directory: /root/.cache/pip/wheels/85/9d/af/01feefbe7d55ef5468796f0c68225b6788e85d9d0a281e7a70\n",
      "Successfully built rouge_score\n",
      "Installing collected packages: filetype, validators, types-requests, types-pyyaml, requests, pypdf, mypy-extensions, marshmallow, fastavro, typing-inspect, rouge_score, groq, dataclasses-json, weaviate-client, langchain-core, bitsandbytes, langchain-text-splitters, langchain-openai, langchain-groq, langchain-google-genai, cohere, trl, langchain-classic, langchain-community, langchain-cohere\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.32.4\n",
      "    Uninstalling requests-2.32.4:\n",
      "      Successfully uninstalled requests-2.32.4\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 1.2.8\n",
      "    Uninstalling langchain-core-1.2.8:\n",
      "      Successfully uninstalled langchain-core-1.2.8\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed bitsandbytes-0.49.1 cohere-5.20.4 dataclasses-json-0.6.7 fastavro-1.12.1 filetype-1.2.0 groq-0.37.1 langchain-classic-1.0.1 langchain-cohere-0.5.0 langchain-community-0.4.1 langchain-core-1.2.10 langchain-google-genai-4.2.0 langchain-groq-1.1.2 langchain-openai-1.1.8 langchain-text-splitters-1.1.0 marshmallow-3.26.2 mypy-extensions-1.1.0 pypdf-6.7.0 requests-2.32.5 rouge_score-0.1.2 trl-0.28.0 types-pyyaml-6.0.12.20250915 types-requests-2.32.4.20260107 typing-inspect-0.9.0 validators-0.35.0 weaviate-client-4.19.2\n"
     ]
    }
   ],
   "source": [
    "! pip install -r \"/content/drive/MyDrive/mini-project-01/requirements.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vwpwhCFat7GL",
   "metadata": {
    "id": "vwpwhCFat7GL"
   },
   "source": [
    "### **Import Reuqired Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d04d50",
   "metadata": {
    "id": "b2d04d50"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "from datasets import load_dataset,Dataset\n",
    "from pathlib import Path\n",
    "import yaml\n",
    "import pandas as pd\n",
    "from transformers import  AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "import os\n",
    "import numpy as np\n",
    "from peft import prepare_model_for_kbit_training,LoraConfig\n",
    "from huggingface_hub import upload_folder\n",
    "from google.colab import userdata\n",
    "from trl import SFTTrainer,SFTConfig\n",
    "from peft import get_peft_model,PeftModel\n",
    "import time\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2svs8lmAxyS_",
   "metadata": {
    "id": "2svs8lmAxyS_"
   },
   "outputs": [],
   "source": [
    "import torch, gc\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "goW1qpvb8YUQ",
   "metadata": {
    "id": "goW1qpvb8YUQ"
   },
   "outputs": [],
   "source": [
    "##ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27356974",
   "metadata": {
    "id": "27356974"
   },
   "source": [
    "### **Enviroment Check**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0d9b01",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25,
     "status": "ok",
     "timestamp": 1770735102605,
     "user": {
      "displayName": "HEMAL MEWANTHA MUNASINGHA",
      "userId": "11358127870633125715"
     },
     "user_tz": -330
    },
    "id": "0c0d9b01",
    "outputId": "a38e71b5-6a41-4876-8f6e-9a677133c3c5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Python Version:3.12.12 (main, Oct 10 2025, 08:52:57) [GCC 11.4.0]\n",
      "Pytorch Version:2.9.0+cu126\n",
      "CUDA is Available:True\n",
      "============================================================\n",
      "============================================================\n",
      "CUDA version: 12.6\n",
      "Device name: NVIDIA A100-SXM4-80GB\n",
      "Device capability: (8, 0)\n",
      "Total VRAM: 79.32 GB\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(f\"Python Version:{sys.version}\")\n",
    "print(f\"Pytorch Version:{torch.__version__}\")\n",
    "print(f\"CUDA is Available:{torch.cuda.is_available()}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"=\"*60)\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"Device name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Device capability: {torch.cuda.get_device_capability(0)}\")\n",
    "    print(f\"Total VRAM: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(\"CUDA is not available!!!!!!!!!!!!!!!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13q4Dwrg9wZy",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1770735109897,
     "user": {
      "displayName": "HEMAL MEWANTHA MUNASINGHA",
      "userId": "11358127870633125715"
     },
     "user_tz": -330
    },
    "id": "13q4Dwrg9wZy",
    "outputId": "36ec12b4-5311-4074-da04-2b3fe634444e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory:/content/drive/MyDrive/mini-project-01\n"
     ]
    }
   ],
   "source": [
    "##current working directory\n",
    "PROJECT_ROOT=Path.cwd()/'drive/MyDrive/mini-project-01'\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "print(f\"Current working directory:{PROJECT_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33e5a4a",
   "metadata": {
    "id": "c33e5a4a"
   },
   "source": [
    "### **Load the yaml file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd079cd",
   "metadata": {
    "id": "6fd079cd"
   },
   "outputs": [],
   "source": [
    "## Load the yaml file\n",
    "def load_yaml(file_path):\n",
    "    with open(file_path,'r') as file:\n",
    "        config=yaml.safe_load(file)\n",
    "\n",
    "    return config\n",
    "\n",
    "\n",
    "##Load the config file\n",
    "config=load_yaml(PROJECT_ROOT/\"config.yaml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e3936c",
   "metadata": {
    "id": "f9e3936c"
   },
   "source": [
    "### **Load the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ff1f0c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "executionInfo": {
     "elapsed": 3131,
     "status": "ok",
     "timestamp": 1770735115948,
     "user": {
      "displayName": "HEMAL MEWANTHA MUNASINGHA",
      "userId": "11358127870633125715"
     },
     "user_tz": -330
    },
    "id": "42ff1f0c",
    "outputId": "3a5fae53-5cfe-4f89-d6ba-6c131453bc75"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89055bffb91c4d00a3bf5c044bc97200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset=load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\"train\":\"/content/drive/MyDrive/mini-project-01/data/final/train.jsonl\"}\n",
    ")\n",
    "\n",
    "train_dataset=dataset[\"train\"]\n",
    "\n",
    "## save the dataset as pandas dataframe\n",
    "train_dataset=pd.DataFrame(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d1cd8f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1770735116388,
     "user": {
      "displayName": "HEMAL MEWANTHA MUNASINGHA",
      "userId": "11358127870633125715"
     },
     "user_tz": -330
    },
    "id": "22d1cd8f",
    "outputId": "a8095a19-ce23-4f94-9869-ab009ded27b2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Display the First 10 rows in the train dataset:\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "summary": "{\n  \"name\": \"train_dataset[:10]\",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"chunk_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30,\n        \"min\": 3,\n        \"max\": 104,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          40,\n          104,\n          39\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 2,\n        \"max\": 10,\n        \"num_unique_values\": 6,\n        \"samples\": [\n          4,\n          6,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"question\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"What types of emergencies and conditions are mentioned that could challenge or limit pricing models?\",\n          \"What potential impact could litigation and arbitration have on the company according to the text?\",\n          \"What might happen to the company's dynamic pricing strategy based on the regulatory environment mentioned in the text?\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"anwser\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"The types of emergencies and conditions mentioned that could challenge or limit pricing models include natural disasters and emergencies.\",\n          \"Litigation and arbitration could have a material impact on the company.\",\n          \"The dynamic pricing strategy may be challenged, banned, limited in emergencies, or capped.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
       "type": "dataframe"
      },
      "text/html": [
       "\n",
       "  <div id=\"df-58c3d4f2-5831-4cfd-b1b8-3e0c1a323e96\" class=\"colab-df-container\">\n",
       "    <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>question_id</th>\n",
       "      <th>question</th>\n",
       "      <th>anwser</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49</td>\n",
       "      <td>4</td>\n",
       "      <td>What percentage of revenue was allocated to ge...</td>\n",
       "      <td>The percentage of revenue allocated to general...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104</td>\n",
       "      <td>6</td>\n",
       "      <td>What potential impact could litigation and arb...</td>\n",
       "      <td>Litigation and arbitration could have a materi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>What type of offerings does the company provid...</td>\n",
       "      <td>The company provides Mobility products and Del...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>4</td>\n",
       "      <td>What could result from the issuance of additio...</td>\n",
       "      <td>The issuance of additional shares of common st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>90</td>\n",
       "      <td>10</td>\n",
       "      <td>Describe the potential financial implications ...</td>\n",
       "      <td>The potential financial implications of recogn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39</td>\n",
       "      <td>6</td>\n",
       "      <td>What might happen to the company's dynamic pri...</td>\n",
       "      <td>The dynamic pricing strategy may be challenged...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>65</td>\n",
       "      <td>8</td>\n",
       "      <td>Given the decrease in total equity from 2022 t...</td>\n",
       "      <td>Given the decrease in total equity from 2022 t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>63</td>\n",
       "      <td>3</td>\n",
       "      <td>What specific aspects of the consolidated fina...</td>\n",
       "      <td>The audits assess the risks of material missta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>40</td>\n",
       "      <td>2</td>\n",
       "      <td>What types of emergencies and conditions are m...</td>\n",
       "      <td>The types of emergencies and conditions mentio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>What are the potential risks associated with c...</td>\n",
       "      <td>The potential risks associated with compliance...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "    <div class=\"colab-df-buttons\">\n",
       "\n",
       "  <div class=\"colab-df-container\">\n",
       "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-58c3d4f2-5831-4cfd-b1b8-3e0c1a323e96')\"\n",
       "            title=\"Convert this dataframe to an interactive table.\"\n",
       "            style=\"display:none;\">\n",
       "\n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
       "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
       "  </svg>\n",
       "    </button>\n",
       "\n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    .colab-df-buttons div {\n",
       "      margin-bottom: 4px;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "    <script>\n",
       "      const buttonEl =\n",
       "        document.querySelector('#df-58c3d4f2-5831-4cfd-b1b8-3e0c1a323e96 button.colab-df-convert');\n",
       "      buttonEl.style.display =\n",
       "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "      async function convertToInteractive(key) {\n",
       "        const element = document.querySelector('#df-58c3d4f2-5831-4cfd-b1b8-3e0c1a323e96');\n",
       "        const dataTable =\n",
       "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                    [key], {});\n",
       "        if (!dataTable) return;\n",
       "\n",
       "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "          + ' to learn more about interactive tables.';\n",
       "        element.innerHTML = '';\n",
       "        dataTable['output_type'] = 'display_data';\n",
       "        await google.colab.output.renderOutput(dataTable, element);\n",
       "        const docLink = document.createElement('div');\n",
       "        docLink.innerHTML = docLinkHtml;\n",
       "        element.appendChild(docLink);\n",
       "      }\n",
       "    </script>\n",
       "  </div>\n",
       "\n",
       "\n",
       "    </div>\n",
       "  </div>\n"
      ],
      "text/plain": [
       "   chunk_id  question_id                                           question  \\\n",
       "0        49            4  What percentage of revenue was allocated to ge...   \n",
       "1       104            6  What potential impact could litigation and arb...   \n",
       "2        21            4  What type of offerings does the company provid...   \n",
       "3        42            4  What could result from the issuance of additio...   \n",
       "4        90           10  Describe the potential financial implications ...   \n",
       "5        39            6  What might happen to the company's dynamic pri...   \n",
       "6        65            8  Given the decrease in total equity from 2022 t...   \n",
       "7        63            3  What specific aspects of the consolidated fina...   \n",
       "8        40            2  What types of emergencies and conditions are m...   \n",
       "9         3            8  What are the potential risks associated with c...   \n",
       "\n",
       "                                              anwser  \n",
       "0  The percentage of revenue allocated to general...  \n",
       "1  Litigation and arbitration could have a materi...  \n",
       "2  The company provides Mobility products and Del...  \n",
       "3  The issuance of additional shares of common st...  \n",
       "4  The potential financial implications of recogn...  \n",
       "5  The dynamic pricing strategy may be challenged...  \n",
       "6  Given the decrease in total equity from 2022 t...  \n",
       "7  The audits assess the risks of material missta...  \n",
       "8  The types of emergencies and conditions mentio...  \n",
       "9  The potential risks associated with compliance...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(f\"Display the First {len(train_dataset[:10])} rows in the train dataset:\")\n",
    "print(\"=\"*60)\n",
    "train_dataset[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f125f57c",
   "metadata": {
    "id": "f125f57c"
   },
   "source": [
    "### **Huggingface Login**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cafc2b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1711,
     "status": "ok",
     "timestamp": 1770735132524,
     "user": {
      "displayName": "HEMAL MEWANTHA MUNASINGHA",
      "userId": "11358127870633125715"
     },
     "user_tz": -330
    },
    "id": "3cafc2b6",
    "outputId": "0304229b-3c1d-441f-9345-4fdc73161147"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Huggingface Login............\n",
      "\u001b[33mA new version of huggingface_hub (1.4.1) is available! You are using version 1.3.7.\n",
      "To update, run: \u001b[1mpip install -U huggingface_hub\u001b[0m\n",
      "\u001b[0m\n",
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `hf`CLI if you want to set the git credential as well.\n",
      "Token is valid (permission: fineGrained).\n",
      "The token `Llama-model-4bit` has been saved to /root/.cache/huggingface/stored_tokens\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful.\n",
      "The current active token is: `Llama-model-4bit`\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Huggingface Login............\")\n",
    "hf_token=userdata.get('HF_TOKEN')\n",
    "!hf auth login --token $hf_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1a521a",
   "metadata": {
    "id": "1d1a521a"
   },
   "source": [
    "### **Check the Token Length Diagnostics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zzHMd8ULiSke",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 162
    },
    "executionInfo": {
     "elapsed": 7559,
     "status": "ok",
     "timestamp": 1770735130809,
     "user": {
      "displayName": "HEMAL MEWANTHA MUNASINGHA",
      "userId": "11358127870633125715"
     },
     "user_tz": -330
    },
    "id": "zzHMd8ULiSke",
    "outputId": "045c072f-9477-40b6-c4cd-1edfabeea030"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Tokenizer:meta-llama/Meta-Llama-3-8B-Instruct\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94dfc13bcce54f1596eff0dc771dd400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/654 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cedc3b3054934aa5ab15d9935ad554c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/51.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8e544ba2e9f4a4c99e24e5089d041f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec306412c5c84011ae62a6d42aa901e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(f\"Loading Tokenizer:{config[\"base_model\"]}\")\n",
    "tokenizer=AutoTokenizer.from_pretrained(config[\"base_model\"],trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68a2203",
   "metadata": {
    "id": "e68a2203"
   },
   "outputs": [],
   "source": [
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token=tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e42f0a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 303,
     "status": "ok",
     "timestamp": 1770735148332,
     "user": {
      "displayName": "HEMAL MEWANTHA MUNASINGHA",
      "userId": "11358127870633125715"
     },
     "user_tz": -330
    },
    "id": "01e42f0a",
    "outputId": "34302d4b-0adb-44e3-e295-0dc813a3b597"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Token Length Diagnostics\n",
      "============================================================\n",
      "Sample Size:904\n",
      "Average Token Lenght:43.7\n",
      "Median Token Length:42.0\n",
      "Minimum Token Length:14\n",
      "Maximum Token Length:89\n",
      "95th percentile of the Token Length:65.8\n",
      "99th percentile of the Token Length:78.0\n"
     ]
    }
   ],
   "source": [
    "tokens_lengths=[]\n",
    "for _,example in train_dataset.iterrows():\n",
    "    text=f\"{example[\"question\"]} {example[\"anwser\"]}\"\n",
    "    tokens=tokenizer(text,add_special_tokens=True)\n",
    "    tokens_lengths.append(len(tokens[\"input_ids\"]))\n",
    "\n",
    "tokens_lengths=np.array(tokens_lengths)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"Token Length Diagnostics\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"Sample Size:{len(train_dataset)}\")\n",
    "print(f\"Average Token Lenght:{tokens_lengths.mean():.1f}\")\n",
    "print(f\"Median Token Length:{np.median(tokens_lengths)}\")\n",
    "print(f\"Minimum Token Length:{np.min(tokens_lengths)}\")\n",
    "print(f\"Maximum Token Length:{np.max(tokens_lengths)}\")\n",
    "print(f\"95th percentile of the Token Length:{np.percentile(tokens_lengths,95):.1f}\")\n",
    "print(f\"99th percentile of the Token Length:{np.percentile(tokens_lengths,99)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28195133",
   "metadata": {
    "id": "28195133"
   },
   "source": [
    "### **Build the prompt format for SFTTrainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3820f7c0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60,
     "status": "ok",
     "timestamp": 1770735153783,
     "user": {
      "displayName": "HEMAL MEWANTHA MUNASINGHA",
      "userId": "11358127870633125715"
     },
     "user_tz": -330
    },
    "id": "3820f7c0",
    "outputId": "6b899d26-fb5e-4838-ab08-6ea8daa598ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Prompts Build for SFT Trainer\n",
      "============================================================\n",
      "Sample Formatted of Prompt:\n",
      "============================================================\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "You are a helpful financial analyst.<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "What percentage of revenue was allocated to general and administrative expenses in 2024?<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
      "\n",
      "The percentage of revenue allocated to general and administrative expenses in 2024 was 8%.<|eot_id|>.....\n"
     ]
    }
   ],
   "source": [
    "def prompt_format(user_text,system_prompt=\"You are a helpful financial analyst.\",assistant_text=None,generation_prompt=False):\n",
    "  ##----Format of CHAT ML------------\n",
    "  messages=[\n",
    "      {\"role\":\"system\",\"content\":system_prompt},\n",
    "      {\"role\":\"user\",\"content\":user_text}\n",
    "  ]\n",
    "  if assistant_text is not None:\n",
    "    messages.append({\"role\":\"assistant\",\"content\":assistant_text})\n",
    "\n",
    "  return tokenizer.apply_chat_template(messages,tokenize=False,add_generation_prompt=generation_prompt)\n",
    "\n",
    "\n",
    "def build_sftt_prompt(row):\n",
    "    \"\"\"\n",
    "     Build the SFTTrainer promtp format using dataset row.\n",
    "     args:row\n",
    "     type:str\n",
    "     return:prompt\n",
    "     type:str\n",
    "    \"\"\"\n",
    "\n",
    "    user_text=row[\"question\"]\n",
    "    assistant_text=row[\"anwser\"]\n",
    "\n",
    "    prompt=prompt_format(\n",
    "        user_text=user_text,\n",
    "        system_prompt=\"You are a helpful financial analyst.\",\n",
    "        assistant_text=assistant_text\n",
    "    )\n",
    "\n",
    "    return {\"text\":prompt}\n",
    "\n",
    "\n",
    "train_dataset_prompt=train_dataset.apply(build_sftt_prompt,axis=1)\n",
    "##val_dataset_prompt=test_dataset.apply(build_sftt_prompt,axis=1)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(f\"Prompts Build for SFT Trainer\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Sample Formatted of Prompt:\")\n",
    "print(\"=\"*60)\n",
    "print(train_dataset_prompt[0][\"text\"][:500]+\".....\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qs2TEA1kkgXm",
   "metadata": {
    "id": "qs2TEA1kkgXm"
   },
   "source": [
    "### **Load the model and apply 4-bit Quantization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fAj0KBTzkhId",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "executionInfo": {
     "elapsed": 122671,
     "status": "ok",
     "timestamp": 1770734786089,
     "user": {
      "displayName": "HEMAL MEWANTHA MUNASINGHA",
      "userId": "11358127870633125715"
     },
     "user_tz": -330
    },
    "id": "fAj0KBTzkhId",
    "outputId": "213ae1bc-ac3a-4f31-a761-175de32e5230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model:meta-llama/Meta-Llama-3-8B-Instruct.....\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d7ac1d46bd644feac6727a28e0c6328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4363517676f743dca103efd8a0718128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "878ea40a58984a3f9907450e0e6afba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0821952ca1f743dabe7c556f2eef773a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36d11bf1986840df9ef91de234d2694f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4-bit quantized model\n"
     ]
    }
   ],
   "source": [
    "## 4-bit Quantization configuration\n",
    "bnb_config=BitsAndBytesConfig(\n",
    "    load_in_4bit=config[\"load_in_4bit\"],\n",
    "    bnb_4bit_compute_dtype=config[\"bnb_4bit_compute_dtype\"],\n",
    "    bnb_4bit_quant_type=config[\"bnb_4bit_quant_type\"],\n",
    "    bnb_4bit_use_double_quant=config[\"bnb_4bit_use_double_quant\"]\n",
    ")\n",
    "\n",
    "## Load the 4-bit quantized model\n",
    "print(f\"Loading base model:{config[\"base_model\"]}.....\")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config[\"base_model\"],\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=\"auto\"\n",
    ")\n",
    "print(\"Loaded 4-bit quantized model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "C_rq1Kfe777B",
   "metadata": {
    "id": "C_rq1Kfe777B"
   },
   "outputs": [],
   "source": [
    "# Convert pandas Series to Hugging Face Dataset\n",
    "train_dataset_hf = Dataset.from_list(train_dataset_prompt.tolist())\n",
    "#val_dataset_hf = Dataset.from_list(train_dataset_prompt.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62187509",
   "metadata": {
    "id": "62187509"
   },
   "source": [
    "### **Prepare Model for LORA Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbf4059",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "executionInfo": {
     "elapsed": 6123,
     "status": "ok",
     "timestamp": 1770734805095,
     "user": {
      "displayName": "HEMAL MEWANTHA MUNASINGHA",
      "userId": "11358127870633125715"
     },
     "user_tz": -330
    },
    "id": "0dbf4059",
    "outputId": "6a45ba20-6a1d-46f5-b232-739549e6e6bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing a model for k-bit Training.....\n",
      "============================================================\n",
      "Applying LORA adapters...\n",
      "trainable params: 41,943,040 || all params: 8,072,204,288 || trainable%: 0.5196\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fb17da7bb8349dd8e609f84bf520a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/904 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6187a0bc40884b31b389179aab6dc734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/904 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99e2f6d65a1c4755b83c9427942893a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/904 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Preparing a model for k-bit Training.....\")\n",
    "model=prepare_model_for_kbit_training(model)\n",
    "\n",
    "## LORA configurations\n",
    "lora_config=LoraConfig(\n",
    "    r=config[\"lora_r\"],\n",
    "    lora_alpha=config[\"lora_alpha\"],\n",
    "    lora_dropout=config[\"lora_dropout\"],\n",
    "    target_modules=config[\"lora_target_modules\"],\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "## Apply LOARA\n",
    "print(\"=\"*60)\n",
    "print(\"Applying LORA adapters...\")\n",
    "model=get_peft_model(model,lora_config)\n",
    "model.print_trainable_parameters()\n",
    "print(\"=\"*60)\n",
    "\n",
    "##Applying Training Arguments\n",
    "training_args=SFTConfig(\n",
    "    output_dir=config[\"output_dir\"],\n",
    "    per_device_train_batch_size=config[\"per_device_train_batch_size\"],\n",
    "    gradient_accumulation_steps=config[\"gradient_accumulation_steps\"],\n",
    "    learning_rate=float(config[\"learning_rate\"]),\n",
    "    num_train_epochs=config[\"num_train_epoch\"],\n",
    "    max_steps=config[\"max_steps\"],\n",
    "    logging_steps=config[\"logging_step\"],\n",
    "    save_steps=config[\"save_steps\"],\n",
    "    fp16=False,\n",
    "    bf16=True,\n",
    "    optim=\"paged_adamw_8bit\",\n",
    "    report_to=\"none\",\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    packing=False,\n",
    "    dataset_text_field=\"text\",\n",
    ")\n",
    "\n",
    "##Create Trainer\n",
    "trainer=SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset_hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TdZrK7iJ8zo2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 892
    },
    "executionInfo": {
     "elapsed": 521934,
     "status": "ok",
     "timestamp": 1770609665295,
     "user": {
      "displayName": "HEMAL MEWANTHA MUNASINGHA",
      "userId": "11358127870633125715"
     },
     "user_tz": -330
    },
    "id": "TdZrK7iJ8zo2",
    "outputId": "f5ee0f30-8daa-4eb2-8b9f-93e2c2d9ce80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING CONFIGURATION\n",
      "============================================================\n",
      "Effective batch size:8\n",
      "Training steps:150\n",
      "Total samples:1200\n",
      "Optimizer: paged_adamw_8bit\n",
      "Learning rate:2e-4\n",
      "LoRA rank:16\n",
      "============================================================\n",
      "\n",
      "🚀 Starting training...\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='150' max='150' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [150/150 08:25, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.119056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.174293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.092363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.029296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.952174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.877987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.869163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.895512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.906642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.930125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.897495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.769131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.739011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>0.733967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.717137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING COMPLETE\n",
      "============================================================\n",
      "Total training time: 521.84s\n",
      "Samples per second: 2.30\n",
      "Steps per second: 0.2870\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TRAINING CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Effective batch size:{config[\"per_device_train_batch_size\"]*config[\"gradient_accumulation_steps\"]}\")\n",
    "print(f\"Training steps:{config[\"max_steps\"]}\")\n",
    "print(f\"Total samples:{config[\"max_steps\"]*config[\"per_device_train_batch_size\"]*config[\"gradient_accumulation_steps\"]}\")\n",
    "print(f\"Optimizer: paged_adamw_8bit\")\n",
    "print(f\"Learning rate:{config[\"learning_rate\"]}\")\n",
    "print(f\"LoRA rank:{config[\"lora_r\"]}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train\n",
    "print(\"\\n🚀 Starting training...\\n\")\n",
    "train_result = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total training time: {train_result.metrics.get('train_runtime', 0):.2f}s\")\n",
    "print(f\"Samples per second: {train_result.metrics.get('train_samples_per_second', 0):.2f}\")\n",
    "print(f\"Steps per second: {train_result.metrics.get('train_steps_per_second', 0):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K2ZUXz5YN2lV",
   "metadata": {
    "id": "K2ZUXz5YN2lV"
   },
   "source": [
    "### **Save Adapters and Tokenizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aCNlxNsEN2PK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "executionInfo": {
     "elapsed": 22083,
     "status": "ok",
     "timestamp": 1770610253290,
     "user": {
      "displayName": "HEMAL MEWANTHA MUNASINGHA",
      "userId": "11358127870633125715"
     },
     "user_tz": -330
    },
    "id": "aCNlxNsEN2PK",
    "outputId": "513b8782-209d-45c1-9c43-0d56f3be3c02"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Saving Adapters to output/adapters....\n",
      "Saved Adapter and Toknizer\n",
      "============================================================\n",
      "============================================================\n",
      "Saving model card.....\n",
      "Model card saved\n",
      "============================================================\n",
      "Pushing to the hugging face Hub:Hemalmewan/uber_finetune_model\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aed99138bd2c4fe7a8b2230b5140e79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031c155bdd5b4698a3f4e91bba5e0ef7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5238f5b910d8409e843eafd7b9b3826a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c05ff663ffc49328e91703152d8a62c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...adapter_model.safetensors:   1%|          |  607kB / 83.9MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617b6ea96c114c9eab496e4f3f8d944a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Files (0 / 0)      : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "578f08281ea34387967c0453907ba718",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "New Data Upload               : |          |  0.00B /  0.00B            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2ae69d6a10a492ca92f8dae952dac69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  ...mpxk2ynfx8/tokenizer.json: 100%|##########| 17.2MB / 17.2MB            "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files have been modified since last commit. Skipping to prevent empty commit.\n",
      "WARNING:huggingface_hub.hf_api:No files have been modified since last commit. Skipping to prevent empty commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pushed to Hub: https://huggingface.co/Hemalmewan/uber_finetune_model\n"
     ]
    }
   ],
   "source": [
    "## Save Adapter and tokenizer\n",
    "print(\"=\"*60)\n",
    "print(f\"Saving Adapters to {config[\"output_dir\"]}....\")\n",
    "trainer.model.save_pretrained(config[\"output_dir\"])\n",
    "tokenizer.save_pretrained(config[\"output_dir\"])\n",
    "print(\"Saved Adapter and Toknizer\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "## Create a model card and saved\n",
    "model_card=f\"\"\"\n",
    "---\n",
    "license: Llama 3 Community License\n",
    "tags:\n",
    "- finance\n",
    "- llm\n",
    "- qlora\n",
    "- llama3\n",
    "- instruction-tuning\n",
    "- annual-report\n",
    "---\n",
    "\n",
    "# Uber 2024 Annual Report – LLaMA-3 QLoRA Adapter\n",
    "\n",
    "This repository contains a **LoRA (Low-Rank Adaptation) adapter** fine-tuned on\n",
    "**instruction–answer pairs derived from Uber’s 2024 Annual Report**.\n",
    "The adapter specializes a general-purpose LLaMA-3-8B model to better understand\n",
    "Uber-specific strategy, financial performance, regulatory risks, and corporate tone.\n",
    "\n",
    "---\n",
    "\n",
    "## Base Model\n",
    "\n",
    "**{config['base_model']}**\n",
    "This adapter must be loaded on top of the base model.\n",
    "\n",
    "---\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The training dataset consists of **synthetic instruction–response pairs**\n",
    "generated from cleaned and chunked sections of the **Uber 2024 Annual Report**.\n",
    "\n",
    "### Dataset Characteristics\n",
    "- Source: Uber 2024 Annual Report (PDF)\n",
    "- Data type: Single-turn instruction–answer pairs\n",
    "- Question types:\n",
    "  - Factual (financial figures, entities)\n",
    "  - Strategic / analytical\n",
    "  - Stylistic / summarization\n",
    "- Train/Test split: Created at chunk level to prevent leakage\n",
    "\n",
    "The dataset was generated using a two-stage LLM pipeline and manually validated\n",
    "for factual faithfulness and hallucination risk.\n",
    "---\n",
    "## Training Method\n",
    "\n",
    "- Fine-tuning method: **QLoRA**\n",
    "- Trainer: `trl.SFTTrainer`\n",
    "- Quantization: **4-bit NF4 with double quantization**\n",
    "- Objective: Supervised instruction fine-tuning\n",
    "\n",
    "---\n",
    "\n",
    "## Training Hyperparameters\n",
    "\n",
    "- LoRA rank (r): {config['lora_r']}\n",
    "- LoRA alpha: {config['lora_alpha']}\n",
    "- LoRA dropout: {config['lora_dropout']}\n",
    "- Target modules: q_proj, k_proj, v_proj, o_proj\n",
    "- Learning rate: {config['learning_rate']}\n",
    "- Max training steps: {config['max_steps']} (≥100)\n",
    "- Effective batch size: {config[\"per_device_train_batch_size\"]*config[\"gradient_accumulation_steps\"]}\n",
    "- Max sequence length: {config['max_token_length']}\n",
    "\n",
    "---\n",
    "\n",
    "## Usage\n",
    "\n",
    "```python\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from trl import SFTTrainer,SFTConfig\n",
    "from peft import get_peft_model\n",
    "from peft import prepare_model_for_kbit_training,LoraConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"{config['base_model']}\",\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "model=prepare_model_for_kbit_training(model)\n",
    "model=get_peft_model(model,lora_config)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"{config['base_model']}\")\n",
    "\n",
    "prompt = \\\"\\\"\\\"### Instruction:\n",
    "What were Uber’s key strategic priorities in 2024?\n",
    "\n",
    "### Response:\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "outputs = model.generate(**inputs, max_new_tokens=384)\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "\n",
    "### Intended Use:\n",
    "-This model is intended for:\n",
    "-**Educational purposes**\n",
    "-Research on instruction tuning\n",
    "-Analysis of corporate disclosures and financial narratives\n",
    "\n",
    "### Limitations & Disclaimer:\n",
    "-This model does not provide financial advice\n",
    "-Outputs may be incomplete or incorrect\n",
    "-Trained on a limited, document-specific dataset\n",
    "-Should not be used for investment or legal decision-making\n",
    "\n",
    "\"\"\"\n",
    "print(\"=\"*60)\n",
    "print(\"Saving model card.....\")\n",
    "with open(os.path.join(config[\"output_dir\"],\"README.md\"),\"w\") as f:\n",
    "  f.write(model_card)\n",
    "\n",
    "print(\"Model card saved\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "##Model push to the huggging face hub\n",
    "config[\"push_to_hub\"]=True\n",
    "if config[\"push_to_hub\"]:\n",
    "  ##create a repo name\n",
    "   repo_id=f\"{config[\"hf_username\"]}/{config[\"hub_model_name\"]}\"\n",
    "\n",
    "   ##pushing to the hugging face\n",
    "   print(f\"Pushing to the hugging face Hub:{repo_id}\")\n",
    "   trainer.model.push_to_hub(repo_id)\n",
    "   tokenizer.push_to_hub(repo_id)\n",
    "\n",
    "   print(f\"✅ Pushed to Hub: https://huggingface.co/{repo_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m47esZRaay2Q",
   "metadata": {
    "id": "m47esZRaay2Q"
   },
   "source": [
    "### **Inference Pipeline(Query Intern)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xTdn5hydTo6h",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "executionInfo": {
     "elapsed": 105373,
     "status": "ok",
     "timestamp": 1770735288550,
     "user": {
      "displayName": "HEMAL MEWANTHA MUNASINGHA",
      "userId": "11358127870633125715"
     },
     "user_tz": -330
    },
    "id": "xTdn5hydTo6h",
    "outputId": "417d015f-702e-4167-f4e8-d824fa09fc93"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading base model...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f215ac3bb124939b1c331e6bddf6342",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2671685e6a90461fa67ee2e33fe05fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (incomplete total...): 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149cfb73aaa240cf805e8b849764af7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3d3f508a0d4021bc411d2804087ea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/291 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42df189641c4400bc6e8fc61c50759c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/187 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading finetuned adapter...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a556716ba5bd4adebf8e7af44fb97bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e659c1121ab411faf00004a5bc387a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/83.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finetuned model ready\n"
     ]
    }
   ],
   "source": [
    "##del model\n",
    "##del trainer\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "print(\"Loading base model...\")\n",
    "base_model_inference = AutoModelForCausalLM.from_pretrained(\n",
    "    config[\"base_model\"],\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True\n",
    "    )\n",
    "\n",
    "print(\"Loading finetuned adapter...\")\n",
    "finetuned_model = PeftModel.from_pretrained(base_model_inference, f\"{config['hf_username']}/{config['hub_model_name']}\")\n",
    "print(\"Finetuned model ready\")\n",
    "\n",
    "def query_intern(user_input,system_prompt=\"You are a helpful financial analyst.\"):\n",
    "\n",
    "    finetuned_model.model.eval()\n",
    "\n",
    "    # Apply chat template to convert messages into a single formatted string\n",
    "    formatted_prompt =prompt_format(user_text=user_input,\n",
    "                                      system_prompt=system_prompt,\n",
    "                                      generation_prompt=True)\n",
    "\n",
    "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(finetuned_model.device)\n",
    "\n",
    "    terminators = [\n",
    "          tokenizer.eos_token_id,\n",
    "          tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "      ]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = finetuned_model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=config[\"max_tokens\"],\n",
    "            do_sample=config[\"do_sample\"],\n",
    "            temperature=config[\"temperature\"],\n",
    "            pad_token_id=tokenizer.pad_token_id,\n",
    "            eos_token_id=terminators,\n",
    "\n",
    "          )\n",
    "\n",
    "    new_tokens = outputs[0][len(inputs.input_ids[0]):]\n",
    "\n",
    "    gen_text = tokenizer.decode(new_tokens, skip_special_tokens=True)\n",
    "\n",
    "    return gen_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Rp_Bd68nQSku",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Rp_Bd68nQSku"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "mount failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-1408506528.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    270\u001b[0m             \u001b[0;34m'https://research.google.com/colaboratory/faq.html#drive-timeout'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m         )\n\u001b[0;32m--> 272\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mount failed'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mextra_reason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcase\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m       \u001b[0;31m# Terminate the DriveFS binary before killing bash.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: mount failed"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "OGvcZpTk8xZC",
   "metadata": {
    "id": "OGvcZpTk8xZC"
   },
   "source": [
    "### **Evaluation using ROUGE-L and LLM-as a judge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Aj_TVefposQK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49
    },
    "executionInfo": {
     "elapsed": 1325,
     "status": "ok",
     "timestamp": 1770735325702,
     "user": {
      "displayName": "HEMAL MEWANTHA MUNASINGHA",
      "userId": "11358127870633125715"
     },
     "user_tz": -330
    },
    "id": "Aj_TVefposQK",
    "outputId": "f9517cae-ee03-40a9-9451-744fe983d96c"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fcd4114064c45cc808c471435110b90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset=load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\"test\":\"/content/drive/MyDrive/mini-project-01/data/final/test.jsonl\"}\n",
    ")\n",
    "\n",
    "## save the dataset as pandas dataframe\n",
    "test_dataset=pd.DataFrame(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "F3TQgR6hDXqT",
   "metadata": {
    "id": "F3TQgR6hDXqT"
   },
   "source": [
    "### **Check the inference time**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F1-2KS9GDWWK",
   "metadata": {
    "id": "F1-2KS9GDWWK"
   },
   "outputs": [],
   "source": [
    "def run_baseline_model(question):\n",
    "    start = time.time()\n",
    "    answer = query_intern(question)   # no retrieval\n",
    "    latency = (time.time() - start) * 1000\n",
    "    return answer, latency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "AK6Xp-85N2hT",
   "metadata": {
    "id": "AK6Xp-85N2hT"
   },
   "source": [
    "### **Evaluating using ROUGE-L**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ohc5b85NN6HN",
   "metadata": {
    "id": "ohc5b85NN6HN"
   },
   "outputs": [],
   "source": [
    "from rouge_score import rouge_scorer\n",
    "\n",
    "scorer=rouge_scorer.RougeScorer(['rougeL'],use_stemmer=True)\n",
    "\n",
    "def rouge_l(prediction, reference):\n",
    "    return scorer.score(reference, prediction)[\"rougeL\"].fmeasure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "_ICDiA2ZT6SA",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 36397,
     "status": "ok",
     "timestamp": 1770735488891,
     "user": {
      "displayName": "HEMAL MEWANTHA MUNASINGHA",
      "userId": "11358127870633125715"
     },
     "user_tz": -330
    },
    "id": "_ICDiA2ZT6SA",
    "outputId": "db028b8b-1ac0-40ef-ce7a-ae5d5944bbf8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Question:How many trading days must the price of the common stock exceed for at least 20 days during a 30-day period for a specific conversion condition?\n",
      "Assistant Answer:The price of the common stock must exceed for at least 20 trading days during a 30-day period.\n",
      "Latency:4287.53 ms\n",
      "Reference Answer:The price of the common stock must exceed for at least 20 trading days during a 30-day period for a specific conversion condition.\n",
      "Rouge-L Score:0.8837\n",
      "============================================================\n",
      "Customer Question:Summarize the implications of failing to comply with healthcare-related regulations as outlined in the report.\n",
      "Assistant Answer:Failing to comply with healthcare-related regulations could lead to fines, penalties, and negative publicity, which could harm the company's reputation and business.\n",
      "Latency:3947.82 ms\n",
      "Reference Answer:Failing to comply with healthcare-related regulations may result in government authorities assessing significant fines.\n",
      "Rouge-L Score:0.4103\n",
      "============================================================\n",
      "Customer Question:What was the balance of intangible assets as of December 31, 2024?\n",
      "Assistant Answer:The balance of intangible assets as of December 31, 2024, was $2,142.\n",
      "Latency:3017.54 ms\n",
      "Reference Answer:The balance of intangible assets as of December 31, 2024, was $1,425.\n",
      "Rouge-L Score:0.8462\n",
      "============================================================\n",
      "Customer Question:How many jurisdictions does the text explicitly mention the company is evaluating for further licenses?\n",
      "Assistant Answer:The text explicitly mentions the company is evaluating jurisdictions in the United States and Europe for further licenses.\n",
      "Latency:2694.61 ms\n",
      "Reference Answer:The text explicitly mentions four jurisdictions the company is evaluating for further licenses.\n",
      "Rouge-L Score:0.7097\n",
      "============================================================\n",
      "Customer Question:Describe the potential impact of Proposition 22 on the company's business model.\n",
      "Assistant Answer:Proposition 22 could impact the company's business model by altering the classification of workers and potentially affecting its operations.\n",
      "Latency:3162.74 ms\n",
      "Reference Answer:Proposition 22 may provide a framework that influences how the company classifies Drivers, potentially allowing for a different business model in California.\n",
      "Rouge-L Score:0.2857\n",
      "============================================================\n",
      "Customer Question:What are the total Platform Participant direct transaction costs for the Mobility segment?\n",
      "Assistant Answer:The total Platform Participant direct transaction costs for the Mobility segment are $1,344.\n",
      "Latency:2378.59 ms\n",
      "Reference Answer:The total Platform Participant direct transaction costs for the Mobility segment were $6,884.\n",
      "Rouge-L Score:0.7857\n",
      "============================================================\n",
      "Customer Question:What percentage of Gross Bookings does the company generate from trips in large metropolitan areas?\n",
      "Assistant Answer:The company generates approximately 70% of its Gross Bookings from trips in large metropolitan areas.\n",
      "Latency:2664.45 ms\n",
      "Reference Answer:The provided text does not contain specific information.\n",
      "Rouge-L Score:0.0870\n",
      "============================================================\n",
      "Customer Question:In what way could the resolution of the CA EDD audit influence the company's operational strategy?\n",
      "Assistant Answer:The resolution of the CA EDD audit could influence the company's operational strategy by potentially impacting the company's ability to operate in California or the need to modify its operations to comply with tax laws.\n",
      "Latency:5279.97 ms\n",
      "Reference Answer:The provided text does not contain specific information.\n",
      "Rouge-L Score:0.0444\n",
      "============================================================\n",
      "Customer Question:How does the company's investment policy limit credit exposure, and what could be the implications of this strategy?\n",
      "Assistant Answer:The company's investment policy limits credit exposure by investing only in high-quality debt securities with a rating of A or better. This strategy could imply a focus on minimizing risk and preserving capital, potentially limiting potential returns.\n",
      "Latency:5664.78 ms\n",
      "Reference Answer:The company's investment policy limits credit exposure by restricting the amount of credit exposure with any one financial institution or commercial issuer. The implications of this strategy could include reduced risk of significant losses from defaults and improved financial stability.\n",
      "Rouge-L Score:0.4000\n",
      "============================================================\n",
      "Customer Question:What is the threshold income mentioned for mobility and delivery earners in Mexico to be classified as employees?\n",
      "Assistant Answer:The threshold income mentioned for mobility and delivery earners in Mexico to be classified as employees is 30,000 Mexican pesos.\n",
      "Latency:3300.04 ms\n",
      "Reference Answer:The threshold income mentioned for mobility and delivery earners in Mexico to be classified as employees is more than one minimum salary a month.\n",
      "Rouge-L Score:0.7556\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for row in test_dataset.iterrows():\n",
    "  answer,latency=run_baseline_model(row[1][\"question\"])\n",
    "\n",
    "  print(f\"Customer Question:{row[1][\"question\"]}\")\n",
    "  print(f\"Assistant Answer:{answer}\")\n",
    "  print(f\"Latency:{latency:.2f} ms\")\n",
    "  print(f\"Reference Answer:{row[1]['anwser']}\")\n",
    "  print(f\"Rouge-L Score:{rouge_l(answer,row[1]['anwser']):.4f}\")\n",
    "  print(\"=\"*60)\n",
    "\n",
    "  i+=1\n",
    "  if i==10:\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RaI21zuDYiX8",
   "metadata": {
    "id": "RaI21zuDYiX8"
   },
   "source": [
    "### **Evaluating using LLM-as a judge**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nBuaVzeeYiHW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1355,
     "status": "ok",
     "timestamp": 1770735521747,
     "user": {
      "displayName": "HEMAL MEWANTHA MUNASINGHA",
      "userId": "11358127870633125715"
     },
     "user_tz": -330
    },
    "id": "nBuaVzeeYiHW",
    "outputId": "a0d8c5bc-6067-4e85-bbf7-fdb4867bf2c1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API key configure with:gpt-4o-mini\n",
      "Using OpenAI package\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "## Openai API key\n",
    "load_dotenv()\n",
    "openai_api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "if not openai_api_key:\n",
    "  print(\"Warning:no API key is found in .env file\")\n",
    "  print(\"Looking for a OpenAI API key....\")\n",
    "  gemini_api_key=input(\"Enter your OpenAI API key:\")\n",
    "\n",
    "  use_llm_as_judge=False\n",
    "  judge_model=False\n",
    "\n",
    "else:\n",
    "  ## Configure Openai with new API key\n",
    "  client_ai=OpenAI(api_key=openai_api_key)\n",
    "  judge_model=client_ai\n",
    "  model_name=\"gpt-4o-mini\"\n",
    "  use_llm_as_judge=True\n",
    "\n",
    "  print(f\"OpenAI API key configure with:{model_name}\")\n",
    "  print(f\"Using OpenAI package\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1GFybtIXiIQw",
   "metadata": {
    "id": "1GFybtIXiIQw"
   },
   "outputs": [],
   "source": [
    "## define the function for llm-as a judge\n",
    "def llm_as_judge(question,prediction,reference):\n",
    "  \"\"\"\n",
    "   Use a OpenAI model(GPT-4o-mini) as judge to check the quality of the answer\n",
    "  \"\"\"\n",
    "  if not use_llm_as_judge:\n",
    "    return None,\"API key is not available\"\n",
    "\n",
    "  judge_prompt=f\"\"\"\n",
    "  You are an expert evaluator for question-answering AI systems.\n",
    "\n",
    "INSTRUCTION (User Question):\n",
    "{question}\n",
    "\n",
    "REFERENCE ANSWER (Ground Truth):\n",
    "{reference}\n",
    "\n",
    "MODEL OUTPUT:\n",
    "{prediction}\n",
    "\n",
    "Evaluate the MODEL OUTPUT using the following criteria:\n",
    "\n",
    "1. **Faithfulness**\n",
    "   - Is the answer strictly supported by the reference?\n",
    "   - Does it avoid hallucinations or unsupported claims?\n",
    "\n",
    "2. **Accuracy**\n",
    "   - Are the facts, numbers, conditions, and entities correct?\n",
    "   - Are there any factual errors or misinterpretations?\n",
    "\n",
    "3. **Completeness**\n",
    "   - Does the answer cover all key points present in the reference?\n",
    "   - Are any important details missing?\n",
    "\n",
    "4. **Clarity & Coherence**\n",
    "   - Is the answer well-structured and easy to understand?\n",
    "   - Is the language concise and unambiguous?\n",
    "\n",
    "5. **Safety & Appropriateness**\n",
    "   - Does the answer avoid unsafe, misleading, or speculative content?\n",
    "   - Does it avoid unnecessary medical/financial/legal advice beyond the reference?\n",
    "\n",
    "---\n",
    "\n",
    "### SCORING INSTRUCTIONS\n",
    "- Assign a **single overall score from 1 to 5**, where:\n",
    "  - **1** = Very poor (incorrect, hallucinated, unsafe)\n",
    "  - **2** = Poor (major issues)\n",
    "  - **3** = Fair (partially correct but incomplete or unclear)\n",
    "  - **4** = Good (mostly correct with minor issues)\n",
    "  - **5** = Excellent (fully correct, faithful, and clear)\n",
    "\n",
    "---\n",
    "\n",
    "### RESPONSE FORMAT (STRICT)\n",
    "Respond using **exactly** the following format:\n",
    "\n",
    "SCORE: [1–5]/5\n",
    "REASONING: [2 concise sentences explaining the score]\n",
    "  \"\"\"\n",
    "\n",
    "  response = judge_model.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert evaluator for question-answering AI systems.\"},\n",
    "            {\"role\": \"user\", \"content\": judge_prompt}\n",
    "        ],\n",
    "        temperature=0.0,\n",
    "    )\n",
    "\n",
    "  return response.choices[0].message.content.strip()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "uD6CvKDPiKh1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 54129,
     "status": "ok",
     "timestamp": 1770735711912,
     "user": {
      "displayName": "HEMAL MEWANTHA MUNASINGHA",
      "userId": "11358127870633125715"
     },
     "user_tz": -330
    },
    "id": "uD6CvKDPiKh1",
    "outputId": "23ee5e2f-0deb-40ed-d5df-a97da07cfa47"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Question:How many trading days must the price of the common stock exceed for at least 20 days during a 30-day period for a specific conversion condition?\n",
      "Assistant Answer:The price of the common stock must exceed for at least 20 trading days during a 30-day period.\n",
      "Latency:3044.66 ms\n",
      "Reference Answer:The price of the common stock must exceed for at least 20 trading days during a 30-day period for a specific conversion condition.\n",
      "LLM-as judge Score:SCORE: 5/5  \n",
      "REASONING: The model output accurately reflects the key condition stated in the reference answer, maintaining both faithfulness and accuracy. It is clear, concise, and free from any unsupported claims or ambiguity.\n",
      "============================================================\n",
      "Customer Question:Summarize the implications of failing to comply with healthcare-related regulations as outlined in the report.\n",
      "Assistant Answer:Failing to comply with healthcare-related regulations could result in fines, penalties, or suspension of operations.\n",
      "Latency:2760.86 ms\n",
      "Reference Answer:Failing to comply with healthcare-related regulations may result in government authorities assessing significant fines.\n",
      "LLM-as judge Score:SCORE: 4/5  \n",
      "REASONING: The model output accurately reflects the potential consequences of non-compliance with healthcare regulations, mentioning fines and penalties, which aligns with the reference. However, it lacks the specific mention of government authorities assessing fines, which is a key detail from the reference, making it slightly less complete.\n",
      "============================================================\n",
      "Customer Question:What was the balance of intangible assets as of December 31, 2024?\n",
      "Assistant Answer:The balance of intangible assets as of December 31, 2024, was $1,421.\n",
      "Latency:3008.03 ms\n",
      "Reference Answer:The balance of intangible assets as of December 31, 2024, was $1,425.\n",
      "LLM-as judge Score:SCORE: 2/5  \n",
      "REASONING: The model output provides an incorrect balance of intangible assets, stating $1,421 instead of the correct amount of $1,425, which constitutes a factual error. Additionally, the output does not include any additional context or details, making it incomplete.\n",
      "============================================================\n",
      "Customer Question:How many jurisdictions does the text explicitly mention the company is evaluating for further licenses?\n",
      "Assistant Answer:The text explicitly mentions the company is evaluating 12 jurisdictions for further licenses.\n",
      "Latency:2119.19 ms\n",
      "Reference Answer:The text explicitly mentions four jurisdictions the company is evaluating for further licenses.\n",
      "LLM-as judge Score:SCORE: 1/5  \n",
      "REASONING: The model output incorrectly states that the company is evaluating 12 jurisdictions, while the reference clearly states it is only four. This significant factual error demonstrates a lack of faithfulness and accuracy.\n",
      "============================================================\n",
      "Customer Question:Describe the potential impact of Proposition 22 on the company's business model.\n",
      "Assistant Answer:Proposition 22 may require the company to modify its business model to comply with the new regulations.\n",
      "Latency:2742.47 ms\n",
      "Reference Answer:Proposition 22 may provide a framework that influences how the company classifies Drivers, potentially allowing for a different business model in California.\n",
      "LLM-as judge Score:SCORE: 3/5  \n",
      "REASONING: The model output captures the essence of the reference answer by indicating a need for modification in the business model, but it lacks the specific mention of how Proposition 22 influences driver classification, which is a key point in the reference. Additionally, the language is somewhat vague, making it less clear and complete compared to the reference.\n",
      "============================================================\n",
      "Customer Question:What are the total Platform Participant direct transaction costs for the Mobility segment?\n",
      "Assistant Answer:The total Platform Participant direct transaction costs for the Mobility segment were $1,444.\n",
      "Latency:2374.72 ms\n",
      "Reference Answer:The total Platform Participant direct transaction costs for the Mobility segment were $6,884.\n",
      "LLM-as judge Score:SCORE: 1/5  \n",
      "REASONING: The model output provides an incorrect figure for the total Platform Participant direct transaction costs for the Mobility segment, stating $1,444 instead of the correct $6,884. This significant factual error undermines the faithfulness and accuracy of the response, leading to a very poor evaluation.\n",
      "============================================================\n",
      "Customer Question:What percentage of Gross Bookings does the company generate from trips in large metropolitan areas?\n",
      "Assistant Answer:The company generates approximately 80% of its Gross Bookings from trips in large metropolitan areas.\n",
      "Latency:2720.83 ms\n",
      "Reference Answer:The provided text does not contain specific information.\n",
      "LLM-as judge Score:SCORE: 1/5  \n",
      "REASONING: The model output provides a specific percentage (80%) that is not supported by the reference, which explicitly states that there is no specific information available. This constitutes a major issue of hallucination and inaccuracy.\n",
      "============================================================\n",
      "Customer Question:In what way could the resolution of the CA EDD audit influence the company's operational strategy?\n",
      "Assistant Answer:The resolution of the CA EDD audit could influence the company's operational strategy by potentially impacting its ability to operate in California or altering its business practices.\n",
      "Latency:4081.19 ms\n",
      "Reference Answer:The provided text does not contain specific information.\n",
      "LLM-as judge Score:SCORE: 3/5  \n",
      "REASONING: The model output provides a plausible interpretation of how the CA EDD audit resolution could influence operational strategy, but it lacks direct support from the reference, which states that it does not contain specific information. Additionally, while the answer is coherent, it does not fully address the absence of details in the reference, leading to a partially correct but incomplete response.\n",
      "============================================================\n",
      "Customer Question:How does the company's investment policy limit credit exposure, and what could be the implications of this strategy?\n",
      "Assistant Answer:The company's investment policy limits credit exposure by not investing in instruments with a maturity of more than one year, which could reduce potential returns but also minimize credit risk.\n",
      "Latency:4429.03 ms\n",
      "Reference Answer:The company's investment policy limits credit exposure by restricting the amount of credit exposure with any one financial institution or commercial issuer. The implications of this strategy could include reduced risk of significant losses from defaults and improved financial stability.\n",
      "LLM-as judge Score:SCORE: 3/5  \n",
      "REASONING: The model output provides a different approach to limiting credit exposure by focusing on maturity rather than the amount of credit exposure with individual institutions, which is a key point in the reference. While it presents a valid strategy, it lacks completeness and does not address the implications of the strategy, making it partially correct but incomplete.\n",
      "============================================================\n",
      "Customer Question:What is the threshold income mentioned for mobility and delivery earners in Mexico to be classified as employees?\n",
      "Assistant Answer:The threshold income mentioned for mobility and delivery earners in Mexico to be classified as employees is 20,000 Mexican pesos (approximately $1,000 USD) per month.\n",
      "Latency:4703.38 ms\n",
      "Reference Answer:The threshold income mentioned for mobility and delivery earners in Mexico to be classified as employees is more than one minimum salary a month.\n",
      "LLM-as judge Score:SCORE: 2/5  \n",
      "REASONING: The model output provides a specific income figure (20,000 Mexican pesos) that is not supported by the reference answer, which states the threshold is \"more than one minimum salary a month.\" This discrepancy indicates a major factual error and misinterpretation of the original information.\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for row in test_dataset.iterrows():\n",
    "  answer,latency=run_baseline_model(row[1][\"question\"])\n",
    "\n",
    "  print(f\"Customer Question:{row[1][\"question\"]}\")\n",
    "  print(f\"Assistant Answer:{answer}\")\n",
    "  print(f\"Latency:{latency:.2f} ms\")\n",
    "  print(f\"Reference Answer:{row[1]['anwser']}\")\n",
    "  print(f\"LLM-as judge Score:{llm_as_judge(row[1][\"question\"],answer,row[1]['anwser'])}\")\n",
    "  print(\"=\"*60)\n",
    "\n",
    "  i+=1\n",
    "  if i==10:\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "L4",
   "machine_shape": "hm",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
