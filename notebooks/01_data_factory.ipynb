{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d97dac6e",
   "metadata": {},
   "source": [
    "### **Import Required Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd11d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pathlib import Path\n",
    "# import sys\n",
    "# PROJECT_ROOT=Path.cwd().parent\n",
    "# sys.path.append(str(PROJECT_ROOT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "06ffe3ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfReader\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "import os\n",
    "from src.services.clean_text import clean_document\n",
    "from src.services.llm_services import llm_configuration\n",
    "from user_prompts.Question_prompt import QUESTION_PROMPT_TEMPLATE\n",
    "from user_prompts.Anwser_prompt import ANWSER_PROMPT_TEMPLATE\n",
    "import re\n",
    "import json\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc60e77",
   "metadata": {},
   "source": [
    "### **Load the PDF File**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "ef8cef4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the yaml file\n",
    "def load_yaml(file_path):\n",
    "    with open(file_path,'r') as file:\n",
    "        config=yaml.safe_load(file)\n",
    "    \n",
    "    return config\n",
    "\n",
    "\n",
    "##Load the config file\n",
    "config=load_yaml(Path.cwd().parent/\"config.yaml\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b0ad1ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Document...\n",
      "============================================================\n",
      "Number of pages in the document:142\n",
      "Number of characters in the document: 640074\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "## Read PDF file and extract text\n",
    "def read_pdf(data_path):\n",
    "    reader=PdfReader(data_path)\n",
    "    text=\"\"\n",
    "    for page in reader.pages:\n",
    "        text+=page.extract_text() + \"\\n\"\n",
    "    return text\n",
    "\n",
    "##Load the data\n",
    "pdf_dir=Path.cwd().parent/config['raw_data_path']\n",
    "pdf_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "pdf_file=list(pdf_dir.glob(\"*.pdf\"))\n",
    "\n",
    "## Read the PDF file\n",
    "document=read_pdf(pdf_file[0])\n",
    "\n",
    "## Number of pages and characters in the document\n",
    "print(\"Loading Document...\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Number of pages in the document:{len(PdfReader(pdf_file[0]).pages)}\")\n",
    "print(f\"Number of characters in the document: {len(document)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2abcb79b",
   "metadata": {},
   "source": [
    "### **Clean Unecessary Things**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "3b114823",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_document=clean_document([document])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "ecc3bc3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters in the cleaned document: 151814\n"
     ]
    }
   ],
   "source": [
    "## After cleaning number of characters\n",
    "print(f\"Number of characters in the cleaned document: {len(cleaned_document[0])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c51847a",
   "metadata": {},
   "source": [
    "### **Chunking Strategy**\n",
    "#### **Fixed Chunking Strategy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "94b4f384",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define function for chunking the text\n",
    "def chunk_text(text,chunk_size=config['chunk_size'],overlap_size=config['overlap_size']):\n",
    "    chunks=[]\n",
    "    start=0\n",
    "    while start < len(text):\n",
    "        end=start+chunk_size\n",
    "        chunk=text[start:end]\n",
    "        chunks.append(chunk)\n",
    "        start+=chunk_size-overlap_size\n",
    "    return chunks\n",
    "\n",
    "\n",
    "# Create chunks from cleaned document\n",
    "text_chunks=chunk_text(cleaned_document[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee92833a",
   "metadata": {},
   "source": [
    "### **Generation Loop**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bc02c2",
   "metadata": {},
   "source": [
    "#### **Step A Question Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b12e4e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks created...\n",
      "============================================================\n",
      "Total number of chunks created:113\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "## Generate 10 Q/A pairs using each chunk\n",
    "print(\"Chunks created...\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total number of chunks created:{len(text_chunks)}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f3d35f",
   "metadata": {},
   "source": [
    "#### **AI model configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "63011bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_model_config=llm_configuration(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "2ef17521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "AI Model Name:gpt-4o-mini\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(f\"AI Model Name:{ai_model_config.model_name}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "545b2697",
   "metadata": {},
   "outputs": [],
   "source": [
    "## call the AI model to generate Q/A pairs\n",
    "def generate_qa_pairs(chunk,chunk_id):\n",
    "    ### define the prompt for question\n",
    "    prompt=QUESTION_PROMPT_TEMPLATE.replace(\"{text_chunk}\",chunk)\n",
    "\n",
    "    ##call the AI client via ChatopenAI\n",
    "    response=ai_model_config.invoke(prompt)\n",
    "    ## generate the 10 questions per chunk\n",
    "    questions=response.content.strip()\n",
    "\n",
    "    result={\n",
    "        \"Chunk ID\":chunk_id,\n",
    "        \"Chunk\":chunk,\n",
    "        \"Gnerated Questions\":questions\n",
    "    }\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7c9bb14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "##define an empty list\n",
    "qa_pairs=[]\n",
    "## loop though each chunk\n",
    "for chunk_id,chunk in enumerate(text_chunks):\n",
    "    qa_pairs.append(generate_qa_pairs(chunk_id=chunk_id,chunk=chunk))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a4866f",
   "metadata": {},
   "source": [
    "#### **Step B Anwser Generation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d68148bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_numbered_answers(answer_text, expected=10):\n",
    "    answers = {}\n",
    "\n",
    "    pattern = r\"(\\d+)\\.\\s+(.*?)(?=\\n\\d+\\.|\\Z)\"\n",
    "    matches = re.findall(pattern, answer_text, re.S)\n",
    "\n",
    "    for num, ans in matches:\n",
    "        answers[int(num)] = ans.strip()\n",
    "\n",
    "    for i in range(1, expected + 1):\n",
    "        answers.setdefault(i, \"\")\n",
    "\n",
    "    return answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "128e29d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "###(optional) remove the leading digit in the question \n",
    "def remove_leading_numbers(question: str) -> str:\n",
    "    return re.sub(r\"^\\s*\\d+\\.\\s*\", \"\", question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c7330f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "## call the AI model to anwser the generated questions of each chunk\n",
    "def generate_anwsers(chunk_id,chunk,generated_questions):\n",
    "    ##define the prompt for anwser\n",
    "    prompt=(\n",
    "        ANWSER_PROMPT_TEMPLATE\n",
    "        .replace(\"{text_chunk}\",chunk)\n",
    "        .replace(\"{questions}\",generated_questions)\n",
    "        \n",
    "        )\n",
    "    \n",
    "   ##call the AI clinet via langchain ChatopenAI\n",
    "    response=ai_model_config.invoke(prompt)\n",
    "   ## Get the answers for each generated question\n",
    "    raw_anwsers=response.content.strip()\n",
    "\n",
    "\n",
    "    ##Parse answers\n",
    "    parsed_answers= parse_numbered_answers(raw_anwsers)\n",
    "\n",
    "    # Split questions into list\n",
    "    question_list = [\n",
    "        q.strip()\n",
    "        for q in generated_questions.split(\"\\n\")\n",
    "        if q.strip()\n",
    "    ]\n",
    "\n",
    "    qa_pairs = []\n",
    "    for i, question in enumerate(question_list, start=1):\n",
    "        qa_pairs.append({\n",
    "            \"question_id\": i,\n",
    "            \"question\": remove_leading_numbers(question),\n",
    "            \"answer\": parsed_answers.get(i, \"\")\n",
    "        })\n",
    "\n",
    "    \n",
    "\n",
    "    return{\n",
    "        \"chunk_id\":chunk_id,\n",
    "        \"qa_pairs\":qa_pairs\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "cd644e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "##define an empty list\n",
    "final_qa_pair=[]\n",
    "for pair in qa_pairs:\n",
    "    final_qa_pair.append(generate_anwsers(pair[\"Chunk ID\"],pair[\"Chunk\"],pair[\"Gnerated Questions\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9a0577",
   "metadata": {},
   "source": [
    "### **Save to JSON file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "5c00c46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path=Path.cwd().parent/config[\"artifacts\"]\n",
    "with open(save_path/\"qa_dataset.json\",\"w\",encoding=\"utf-8\") as f:\n",
    "     json.dump(final_qa_pair,f,indent=2,ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206127d6",
   "metadata": {},
   "source": [
    "### **Split the Data into Training and Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ec09734b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## flattend the dataset\n",
    "def flattend_qa_dataset(final_qa_pair):\n",
    "     flattend_data=[] ##defined an empty list\n",
    "     for chunk in final_qa_pair:\n",
    "          chunk_id=chunk[\"chunk_id\"]\n",
    "          for qa in chunk[\"qa_pairs\"]:\n",
    "               flattend_data.append({\n",
    "                    \"chunk_id\":chunk_id,\n",
    "                    \"question_id\":qa[\"question_id\"],\n",
    "                    \"question\":qa[\"question\"],\n",
    "                    \"anwser\":qa[\"answer\"]\n",
    "\n",
    "               })\n",
    "     return flattend_data\n",
    "\n",
    "##call the function\n",
    "flattend_data=flattend_qa_dataset(final_qa_pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "21d78f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "##divide the dataset into train and testing\n",
    "def train_test_split(data,train_ratio=config[\"train_ratio\"],seed=42):\n",
    "    random.seed(seed)\n",
    "    random.shuffle(data)\n",
    "\n",
    "    split_idx=int(len(data)*train_ratio) ##get the cuting benchmark\n",
    "\n",
    "    train_data=data[:split_idx]\n",
    "    test_data=data[split_idx:]\n",
    "\n",
    "    return train_data,test_data\n",
    "\n",
    "##call the function\n",
    "train_data,test_data=train_test_split(flattend_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c5ca9170",
   "metadata": {},
   "outputs": [],
   "source": [
    "##save the file as jsonl format\n",
    "def save_jsonl(data, file_path):\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for item in data:\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "##call the function\n",
    "save_jsonl(data=train_data,file_path=Path.cwd().parent/config[\"final\"]/\"train.jsonl\")\n",
    "save_jsonl(data=test_data,file_path=Path.cwd().parent/config[\"final\"]/\"test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014b9077",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
